{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOPQ20QOosXZ3fEecYGzH6U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9eba4a1c436b461bb8ada4d9d782c9fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e690744cdb1b46419ac0f66379de875d","IPY_MODEL_9517f4b31d8348e199e7bbe04b9c1fd1","IPY_MODEL_015af70eeb7343dcbbf6630e8b44dfa0"],"layout":"IPY_MODEL_7d1e04e15ec34fab85bfda890f76d15c"}},"e690744cdb1b46419ac0f66379de875d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c72a6ef3ec44268a9ce17cbec72b4f6","placeholder":"‚Äã","style":"IPY_MODEL_61db315543da4bdb9be87e8a4bac4d4a","value":"Fetching‚Äá4‚Äáfiles:‚Äá100%"}},"9517f4b31d8348e199e7bbe04b9c1fd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bff4d5f10d840d491b3eabe98e00ef1","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be5dbc415f1544a4a919c79e24a739e8","value":4}},"015af70eeb7343dcbbf6630e8b44dfa0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f190a5da2314c469fa1a3eb7f7af12c","placeholder":"‚Äã","style":"IPY_MODEL_df028d7501b04f9eb06a0e40f194a516","value":"‚Äá4/4‚Äá[00:00&lt;00:00,‚Äá412.56it/s]"}},"7d1e04e15ec34fab85bfda890f76d15c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c72a6ef3ec44268a9ce17cbec72b4f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61db315543da4bdb9be87e8a4bac4d4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bff4d5f10d840d491b3eabe98e00ef1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be5dbc415f1544a4a919c79e24a739e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f190a5da2314c469fa1a3eb7f7af12c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df028d7501b04f9eb06a0e40f194a516":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["import os, sys\n","\n","# Clone repo\n","if not os.path.exists('/content/qwen3_tts'):\n","    os.system('git clone https://github.com/QwenLM/Qwen3-TTS /content/qwen3_tts')\n","else:\n","    print(\"‚úÖ Repo gi√† presente\")\n","\n","# Dipendenze esatte da pyproject.toml\n","os.system('pip install -q transformers==4.57.3 accelerate==1.12.0')\n","os.system('pip install -q soundfile librosa torchaudio onnxruntime einops sox')\n","\n","# Installa il pacchetto qwen_tts (senza -e)\n","os.system('pip install -q /content/qwen3_tts')\n","\n","# Dipendenze per le funzioni extra\n","os.system('pip install -q gradio pydub pyloudnorm noisereduce')\n","\n","print(\"‚úÖ Tutto installato. Riavvio...\")\n","os.kill(os.getpid(), 9)\n"],"metadata":{"id":"hKAgXo39QfBI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys, torch\n","\n","# Doppia sicurezza: sia pip che path diretto\n","sys.path.insert(0, '/content/qwen3_tts')\n","\n","from qwen_tts import Qwen3TTSModel\n","\n","print(f\"‚úÖ Python: {sys.version[:6]}\")\n","print(f\"‚úÖ Qwen3TTSModel importato\")\n","print(f\"üéÆ CUDA: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free  = torch.cuda.mem_get_info()[0] / 1024**3\n","    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n","    print(f\"   VRAM: {free:.1f}GB liberi / {total:.1f}GB totali\")\n","else:\n","    print(\"‚ö†Ô∏è Nessuna GPU ‚Üí vai su Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGr3UCcUQpy_","executionInfo":{"status":"ok","timestamp":1771594534494,"user_tz":-60,"elapsed":21020,"user":{"displayName":"Lorenzo Nardi","userId":"06642846607330582136"}},"outputId":"a74f1dc5-dc88-44d4-9a35-66f6c95b35e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:sox:SoX could not be found!\n","\n","    If you do not have SoX, proceed here:\n","     - - - http://sox.sourceforge.net/ - - -\n","\n","    If you do (or think that you should) have SoX, double-check your\n","    path variables.\n","    \n"]},{"output_type":"stream","name":"stdout","text":["\n","********\n","Warning: flash-attn is not installed. Will only run the manual PyTorch version. Please install flash-attn for faster inference.\n","********\n"," \n","‚úÖ Python: 3.12.1\n","‚úÖ Qwen3TTSModel importato\n","üéÆ CUDA: True\n","   GPU: Tesla T4\n","   VRAM: 14.5GB liberi / 14.6GB totali\n"]}]},{"cell_type":"code","source":["print(\"üì¶ Caricamento Qwen3-TTS 1.7B Base (3-5 min)...\")\n","\n","model = Qwen3TTSModel.from_pretrained(\n","    \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\",\n","    device_map=\"cuda:0\",\n","    dtype=torch.float16,\n","    attn_implementation=\"sdpa\",\n",")\n","\n","SAMPLE_RATE = 24000\n","print(\"‚úÖ Modello pronto!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["9eba4a1c436b461bb8ada4d9d782c9fd","e690744cdb1b46419ac0f66379de875d","9517f4b31d8348e199e7bbe04b9c1fd1","015af70eeb7343dcbbf6630e8b44dfa0","7d1e04e15ec34fab85bfda890f76d15c","9c72a6ef3ec44268a9ce17cbec72b4f6","61db315543da4bdb9be87e8a4bac4d4a","7bff4d5f10d840d491b3eabe98e00ef1","be5dbc415f1544a4a919c79e24a739e8","8f190a5da2314c469fa1a3eb7f7af12c","df028d7501b04f9eb06a0e40f194a516"]},"id":"VeX5UMsDRX_w","executionInfo":{"status":"ok","timestamp":1771594693823,"user_tz":-60,"elapsed":14052,"user":{"displayName":"Lorenzo Nardi","userId":"06642846607330582136"}},"outputId":"209eeb94-0330-4eee-863d-685fc71841db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Caricamento Qwen3-TTS 1.7B Base (3-5 min)...\n"]},{"output_type":"display_data","data":{"text/plain":["Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eba4a1c436b461bb8ada4d9d782c9fd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Modello pronto!\n"]}]},{"cell_type":"code","source":["import os, time, hashlib, tempfile, re, subprocess, sys, importlib.util\n","import gradio as gr\n","import torch, numpy as np\n","import librosa, soundfile as sf\n","from pydub import AudioSegment\n","from pydub.silence import detect_leading_silence\n","import pyloudnorm as pyln\n","import noisereduce as nr\n","\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","# (1) Whisper per auto-trascrizione reference\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","if importlib.util.find_spec(\"faster_whisper\") is None:\n","    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"faster-whisper\"], check=True)\n","\n","from faster_whisper import WhisperModel\n","\n","_whisper = None\n","def get_whisper(model_size=\"base\"):\n","    global _whisper\n","    if _whisper is None or getattr(_whisper, \"_size\", None) != model_size:\n","        # base/small sono un buon compromesso su Colab T4\n","        _whisper = WhisperModel(model_size, device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n","                                compute_type=\"float16\" if torch.cuda.is_available() else \"int8\")\n","        _whisper._size = model_size\n","    return _whisper\n","\n","def trascrivi_reference(audio_path, lang=\"it\", whisper_size=\"base\"):\n","    wm = get_whisper(whisper_size)\n","    segments, info = wm.transcribe(audio_path, language=lang, vad_filter=True)\n","    text = \" \".join([s.text.strip() for s in segments]).strip()\n","    return text\n","\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","# (2) Preprocessing testo IT (evita ‚Äúpunto‚Äù, virgolette, ecc.)\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","def preprocessa_testo_it(testo: str):\n","    testo = testo.replace('¬´','').replace('¬ª','')\n","    testo = testo.replace('\"','')\n","    testo = testo.replace('\\u2018',\"'\").replace('\\u2019',\"'\")  # apostrofi tipografici\n","    # '.' a fine frase -> ',' (pausa senza ‚Äúpunto‚Äù)\n","    testo = re.sub(r'\\.(\\s+|$)', r',\\1', testo)\n","    # puntini -> virgola\n","    testo = testo.replace('‚Ä¶', ',')\n","    testo = re.sub(r'\\.{2,}', ',', testo)\n","    # trattini lunghi -> virgola\n","    testo = testo.replace('‚Äî', ',').replace('‚Äì', ',')\n","    # parentesi via\n","    testo = re.sub(r'[()[\\]{}]', '', testo)\n","    # spazi multipli\n","    testo = re.sub(r'\\s+', ' ', testo).strip()\n","    return testo\n","\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","# (3) Reference audio: MP3/WAV lungo -> chunk ‚Äúmigliore‚Äù 15‚Äì20s\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","def trim_silence(audio, threshold=-40, padding_ms=120):\n","    start = detect_leading_silence(audio, silence_threshold=threshold)\n","    end   = detect_leading_silence(audio.reverse(), silence_threshold=threshold)\n","    trimmed = audio[start : len(audio) - end]\n","    pad = AudioSegment.silent(duration=padding_ms)\n","    return pad + trimmed + pad\n","\n","def prepara_reference(filepath, denoise=False, target_ms=18_000):\n","    audio = AudioSegment.from_file(filepath)\n","    audio = audio.set_channels(1).set_frame_rate(22050)\n","    audio = trim_silence(audio)\n","\n","    # Se lungo: estrai finestra pi√π parlata (RMS max)\n","    if len(audio) > target_ms:\n","        step = 1500\n","        chunks = [audio[i:i+target_ms] for i in range(0, len(audio) - target_ms, step)]\n","        audio = max(chunks, key=lambda c: c.rms)\n","\n","    tmp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n","    audio.export(tmp.name, format=\"wav\")\n","\n","    if denoise:\n","        data, sr = sf.read(tmp.name)\n","        data = nr.reduce_noise(y=data, sr=sr, prop_decrease=0.75)\n","        sf.write(tmp.name, data, sr)\n","\n","    return tmp.name\n","\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","# (4) Post-processing output: trim + LUFS\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","def postprocessa_output(wav_path, target_lufs=-18.0):\n","    audio = AudioSegment.from_wav(wav_path)\n","    audio = trim_silence(audio, threshold=-50, padding_ms=150)\n","    audio.export(wav_path, format=\"wav\")\n","\n","    data, rate = sf.read(wav_path)\n","    meter = pyln.Meter(rate)\n","    loudness = meter.integrated_loudness(data)\n","    if loudness > -70:\n","        data = pyln.normalize.loudness(data, loudness, target_lufs)\n","        sf.write(wav_path, data, rate)\n","    return wav_path\n","\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","# (5) Target durata (pitch-preserving time-stretch)\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","def durata_wav(path):\n","    data, rate = sf.read(path)\n","    return len(data) / rate\n","\n","def adatta_durata(wav_path, target_sec):\n","    data, sr = sf.read(wav_path)\n","    current_sec = len(data) / sr\n","    rate = current_sec / target_sec\n","    rate = max(0.7, min(1.4, rate))  # range ‚Äúsicuro‚Äù\n","    stretched = librosa.effects.time_stretch(data.astype(np.float32), rate=rate)\n","    sf.write(wav_path, stretched, sr)\n","    return wav_path, rate, current_sec\n","\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","# (6) Cache voice_clone_prompt (velocizza ripetizioni)\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","def _hash_file(path):\n","    with open(path, \"rb\") as f:\n","        return hashlib.md5(f.read()).hexdigest()\n","\n","_prompt_cache = {}\n","def get_voice_prompt(ref_wav, ref_text, xvec_only):\n","    key = (_hash_file(ref_wav), ref_text, bool(xvec_only))\n","    if key not in _prompt_cache:\n","        _prompt_cache[key] = model.create_voice_clone_prompt(\n","            ref_audio=ref_wav,\n","            ref_text=ref_text,\n","            x_vector_only_mode=bool(xvec_only),\n","        )\n","    return _prompt_cache[key]\n","\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","# (7) Preset ‚ÄúItalian-friendly‚Äù (valori conservativi)\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","PRESET = {\n","    \"üáÆüáπ IT ‚Äì Naturale YouTube (consigliato)\": dict(\n","        temperature=0.85, top_p=0.95, top_k=50, repetition_penalty=1.06,\n","        max_new_tokens=3072\n","    ),\n","    \"üáÆüáπ IT ‚Äì Super stabile (meno errori)\": dict(\n","        temperature=0.70, top_p=0.85, top_k=40, repetition_penalty=1.10,\n","        max_new_tokens=3072\n","    ),\n","    \"üáÆüáπ IT ‚Äì Pi√π espressivo (rischio errori)\": dict(\n","        temperature=1.00, top_p=0.95, top_k=70, repetition_penalty=1.05,\n","        max_new_tokens=3072\n","    ),\n","}\n","\n","def applica_preset(nome):\n","    p = PRESET[nome]\n","    return p[\"temperature\"], p[\"top_p\"], p[\"top_k\"], p[\"repetition_penalty\"], p[\"max_new_tokens\"]\n","\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","# (8) Generazione Qwen Voice Clone\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","def genera_qwen_it(\n","    testo, ref_file,\n","    ref_text_manual,\n","    auto_ref_text, whisper_size,\n","    xvec_only, use_cache,\n","    denoise_ref, do_postprocess,\n","    preset_name,\n","    temperature, top_p, top_k, repetition_penalty, max_new_tokens,\n","    target_min, target_sec,\n","):\n","    if not testo or not testo.strip():\n","        raise gr.Error(\"Inserisci un testo.\")\n","    if ref_file is None:\n","        raise gr.Error(\"Carica un audio di riferimento.\")\n","\n","    t0 = time.time()\n","    target_totale = float(target_min) * 60 + float(target_sec)\n","\n","    testo_proc = preprocessa_testo_it(testo)\n","\n","    # prepara reference (estrae chunk migliore se lungo)\n","    ref_wav = prepara_reference(ref_file, denoise=denoise_ref, target_ms=18_000)\n","\n","    # ref_text: manuale > auto(whisper) > vuoto\n","    ref_text = (ref_text_manual or \"\").strip()\n","    if (not xvec_only) and (not ref_text) and auto_ref_text:\n","        ref_text = trascrivi_reference(ref_wav, lang=\"it\", whisper_size=whisper_size)\n","\n","    # Avviso utile: se xvec_only=False e ref_text vuoto, la qualit√† pu√≤ peggiorare\n","    warn = \"\"\n","    if (not xvec_only) and (not ref_text):\n","        warn = \"‚ö†Ô∏è ref_text vuoto con x_vector_only_mode=False: meglio inserire o auto-trascrivere.\"\n","\n","    gen_kwargs = dict(\n","        max_new_tokens=int(max_new_tokens),\n","        do_sample=True,\n","        top_k=int(top_k),\n","        top_p=float(top_p),\n","        temperature=float(temperature),\n","        repetition_penalty=float(repetition_penalty),\n","        subtalker_dosample=True,\n","        subtalker_top_k=int(top_k),\n","        subtalker_top_p=float(top_p),\n","        subtalker_temperature=float(temperature),\n","    )\n","\n","    if use_cache:\n","        prompt = get_voice_prompt(ref_wav, ref_text, xvec_only)\n","        wavs, sr = model.generate_voice_clone(\n","            text=testo_proc,\n","            language=\"Italian\",\n","            voice_clone_prompt=prompt,\n","            **gen_kwargs,\n","        )\n","    else:\n","        wavs, sr = model.generate_voice_clone(\n","            text=testo_proc,\n","            language=\"Italian\",\n","            ref_audio=ref_wav,\n","            ref_text=ref_text,\n","            x_vector_only_mode=bool(xvec_only),\n","            **gen_kwargs,\n","        )\n","\n","    out_path = \"/content/output_qwen3_it.wav\"\n","    sf.write(out_path, wavs[0], sr)\n","\n","    # target durata\n","    stretch = 1.0\n","    if target_totale > 0:\n","        out_path, stretch, _ = adatta_durata(out_path, target_totale)\n","\n","    if do_postprocess:\n","        postprocessa_output(out_path, target_lufs=-18.0)\n","\n","    dur = durata_wav(out_path)\n","    info = f\"‚úÖ {time.time()-t0:.1f}s | durata {dur:.1f}s | preset: {preset_name} | stretch {stretch:.3f}x\"\n","    if target_totale > 0:\n","        info += f\" | delta {dur-target_totale:+.1f}s\"\n","    if warn:\n","        info = warn + \"\\n\" + info\n","\n","    return out_path, testo_proc, ref_text, info\n","\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","# (9) Gradio UI\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","with gr.Blocks(title=\"Qwen3-TTS ‚Äî Voice Clone IT Pro\") as ui:\n","    gr.Markdown(\"# Qwen3‚ÄëTTS ‚Äî Voice Cloning Italiano (Pro)\")\n","    gr.Markdown(\"Nota: lo **stile vocale** non √® un parametro della modalit√† Voice Clone; la qualit√† in Voice Clone migliora soprattutto con ref_text (qui puoi auto‚Äëtrascriverlo).\")\n","\n","    with gr.Row():\n","        with gr.Column(scale=1):\n","            ref_audio = gr.Audio(label=\"üé§ Reference (WAV/MP3, anche lungo)\", type=\"filepath\", sources=[\"upload\"])\n","\n","            ref_text_manual = gr.Textbox(\n","                label=\"üìù Trascrizione reference (migliora fedelt√†)\",\n","                placeholder=\"Se la inserisci √® meglio. In alternativa attiva auto‚Äëtrascrizione.\",\n","                lines=2\n","            )\n","\n","            auto_ref_text = gr.Checkbox(label=\"üß† Auto‚Äëtrascrivi reference (Whisper)\", value=True)\n","            whisper_size = gr.Dropdown(label=\"Whisper model\", choices=[\"tiny\",\"base\",\"small\"], value=\"base\")\n","\n","            xvec_only = gr.Checkbox(\n","                label=\"‚ö° x_vector_only_mode (non richiede trascrizione, qualit√† inferiore)\",\n","                value=False\n","            )\n","            use_cache = gr.Checkbox(label=\"‚ö° Cache voice_clone_prompt (consigliato)\", value=True)\n","\n","            with gr.Row():\n","                denoise_ref = gr.Checkbox(label=\"üîá Denoise reference\", value=False)\n","                do_postprocess = gr.Checkbox(label=\"üéöÔ∏è Normalizza output (-18 LUFS)\", value=True)\n","\n","            preset_dd = gr.Dropdown(\n","                label=\"üéõÔ∏è Preset IT\",\n","                choices=list(PRESET.keys()),\n","                value=\"üáÆüáπ IT ‚Äì Naturale YouTube (consigliato)\"\n","            )\n","\n","            gr.Markdown(\"### üé¨ Target durata (opzionale)\")\n","            with gr.Row():\n","                target_min = gr.Number(label=\"Min\", value=0, minimum=0, maximum=60, step=1)\n","                target_sec = gr.Number(label=\"Sec\", value=0, minimum=0, maximum=59, step=1)\n","\n","            with gr.Accordion(\"‚öôÔ∏è Avanzate\", open=False):\n","                temperature = gr.Slider(label=\"temperature\", minimum=0.3, maximum=1.3, value=0.85, step=0.05)\n","                top_p = gr.Slider(label=\"top_p\", minimum=0.5, maximum=1.0, value=0.95, step=0.05)\n","                top_k = gr.Slider(label=\"top_k\", minimum=1, maximum=200, value=50, step=1)\n","                repetition_penalty = gr.Slider(label=\"repetition_penalty\", minimum=1.0, maximum=1.3, value=1.06, step=0.01)\n","                max_new_tokens = gr.Slider(label=\"max_new_tokens\", minimum=512, maximum=8192, value=3072, step=256)\n","\n","            preset_dd.change(\n","                fn=applica_preset,\n","                inputs=preset_dd,\n","                outputs=[temperature, top_p, top_k, repetition_penalty, max_new_tokens]\n","            )\n","\n","        with gr.Column(scale=1):\n","            testo_input = gr.Textbox(label=\"üìÑ Testo (Italiano)\", lines=12, placeholder=\"Incolla qui il tuo voiceover in italiano‚Ä¶\")\n","            btn = gr.Button(\"üöÄ Genera\", variant=\"primary\")\n","            audio_out = gr.Audio(label=\"üîä Output\", type=\"filepath\")\n","            testo_proc_out = gr.Textbox(label=\"Testo preprocessato\", lines=3)\n","            ref_text_out = gr.Textbox(label=\"ref_text usato (manuale o auto)\", lines=3)\n","            info_out = gr.Textbox(label=\"Info\", lines=3)\n","\n","    btn.click(\n","        fn=genera_qwen_it,\n","        inputs=[\n","            testo_input, ref_audio,\n","            ref_text_manual,\n","            auto_ref_text, whisper_size,\n","            xvec_only, use_cache,\n","            denoise_ref, do_postprocess,\n","            preset_dd,\n","            temperature, top_p, top_k, repetition_penalty, max_new_tokens,\n","            target_min, target_sec,\n","        ],\n","        outputs=[audio_out, testo_proc_out, ref_text_out, info_out]\n","    )\n","\n","ui.queue(default_concurrency_limit=1)\n","ui.launch(share=True)\n"],"metadata":{"id":"W3OaoOmqS4sX","executionInfo":{"status":"ok","timestamp":1771595090675,"user_tz":-60,"elapsed":14312,"user":{"displayName":"Lorenzo Nardi","userId":"06642846607330582136"}},"outputId":"cfefbd3e-417c-4a5c-e9df-6998e195173f","colab":{"base_uri":"https://localhost:8080/","height":591}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://b5786121738a56b93a.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://b5786121738a56b93a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":5}]}]}