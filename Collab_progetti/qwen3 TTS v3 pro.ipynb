{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os, sys, subprocess\n",
    "\n",
    "# Clone repo\n",
    "if not os.path.exists('/content/qwen3_tts'):\n",
    "    os.system('git clone https://github.com/QwenLM/Qwen3-TTS /content/qwen3_tts')\n",
    "else:\n",
    "    print('\u2705 Repo gi\u00e0 presente')\n",
    "\n",
    "# ── Sistema (sox binario + rubberband) ──────────────────────────\n",
    "# FIX: pydub cerca il BINARIO sox nel PATH, non il package pip\n",
    "os.system('apt-get install -y -q sox libsox-fmt-all rubberband-cli')\n",
    "\n",
    "# ── Python deps ────────────────────────────────────────\n",
    "os.system('pip install -q transformers==4.57.3 accelerate==1.12.0')\n",
    "os.system('pip install -q soundfile librosa torchaudio onnxruntime einops sox')\n",
    "os.system('pip install -q /content/qwen3_tts')\n",
    "os.system('pip install -q gradio pydub pyloudnorm noisereduce')\n",
    "os.system('pip install -q pyrubberband')\n",
    "\n",
    "# ── flash-attn (opzionale, ~20% pi\u00f9 veloce) ────────────────────\n",
    "# Su Colab T4 + Python 3.12 non esiste un wheel pre-compilato:\n",
    "# pip tenta di compilare dal sorgente (>10 min). Lo saltiamo dopo\n",
    "# 90s e usiamo sdpa (PyTorch nativo, funziona perfettamente).\n",
    "print('\u23f3 Verifica flash-attn (max 90s)...')\n",
    "_fa_proc = subprocess.Popen(\n",
    "    [sys.executable, '-m', 'pip', 'install', 'flash-attn', '-q'],\n",
    "    stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    ")\n",
    "try:\n",
    "    _out, _err = _fa_proc.communicate(timeout=90)\n",
    "    if _fa_proc.returncode == 0:\n",
    "        print('\u2705 flash-attn installato! (inferenza pi\u00f9 veloce)')\n",
    "    else:\n",
    "        print('\u2139\ufe0f flash-attn non disponibile \u2192 si usa sdpa (ok)')\n",
    "except subprocess.TimeoutExpired:\n",
    "    _fa_proc.kill()\n",
    "    _fa_proc.communicate()  # svuota i buffer, evita zombie\n",
    "    print('\u2139\ufe0f flash-attn richiede compilazione (>10 min) \u2192 saltato, si usa sdpa')\n",
    "except Exception as _e:\n",
    "    print(f'\u2139\ufe0f flash-attn: {_e} \u2192 si usa sdpa')\n",
    "\n",
    "print('\u2705 Tutto installato. Riavvio...')\n",
    "os.kill(os.getpid(), 9)\n"
   ],
   "metadata": {"id": "cell_install"},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import sys, torch\n",
    "\n",
    "sys.path.insert(0, '/content/qwen3_tts')\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "# NOTA: il warning 'flash-attn is not installed' qui sotto \u00e8 normale\n",
    "#       e ININFLUENTE: la libreria usa PyTorch sdpa che funziona perfettamente\n",
    "\n",
    "print(f'\u2705 Python: {sys.version[:6]}')\n",
    "print(f'\u2705 Qwen3TTSModel importato')\n",
    "print(f'\ud83c\udfae CUDA: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    free  = torch.cuda.mem_get_info()[0] / 1024**3\n",
    "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'   VRAM: {free:.1f}GB liberi / {total:.1f}GB totali')\n",
    "else:\n",
    "    print('\u26a0\ufe0f Nessuna GPU \u2192 vai su Runtime \u2192 Change runtime type \u2192 T4 GPU')\n"
   ],
   "metadata": {"id": "cell_check"},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print('\ud83d\udce6 Caricamento modello...')\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# Scegli il modello (decommenta quello che vuoi):\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "MODEL_ID = \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\"          # Voice Clone standard\n",
    "# MODEL_ID = \"Qwen/Qwen3-TTS-12Hz-0.6B-Base\"        # Voice Clone veloce (met\u00e0 VRAM)\n",
    "# MODEL_ID = \"Qwen/Qwen3-TTS-25Hz-1.7B-Base\"        # Voice Clone long-form (>500 parole)\n",
    "# MODEL_ID = \"Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign\" # Crea voce da descrizione testuale\n",
    "# MODEL_ID = \"Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\" # 9 voci predefinite Qwen\n",
    "\n",
    "# Detect flash-attn\n",
    "try:\n",
    "    import flash_attn\n",
    "    attn_impl = \"flash_attention_2\"\n",
    "    print('\u26a1 flash-attn rilevato \u2192 flash_attention_2')\n",
    "except ImportError:\n",
    "    attn_impl = \"sdpa\"\n",
    "    print('\u2139\ufe0f flash-attn non trovato \u2192 sdpa (ok, differenza ~15%)')\n",
    "\n",
    "model = Qwen3TTSModel.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"cuda:0\",\n",
    "    dtype=torch.bfloat16,\n",
    "    attn_implementation=attn_impl,\n",
    ")\n",
    "\n",
    "if \"VoiceDesign\" in MODEL_ID:\n",
    "    MODEL_TYPE = \"design\"\n",
    "elif \"CustomVoice\" in MODEL_ID:\n",
    "    MODEL_TYPE = \"custom\"\n",
    "else:\n",
    "    MODEL_TYPE = \"clone\"\n",
    "\n",
    "SAMPLE_RATE = 25000 if \"25Hz\" in MODEL_ID else 24000\n",
    "print(f\"\u2705 Modello pronto! | tipo: {MODEL_TYPE} | SR: {SAMPLE_RATE} Hz | attn: {attn_impl}\")\n"
   ],
   "metadata": {"id": "cell_model"},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os, time, hashlib, tempfile, re, subprocess, sys, importlib.util\n",
    "import gradio as gr\n",
    "import torch, numpy as np\n",
    "import librosa, soundfile as sf\n",
    "import pyrubberband as pyrb\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_leading_silence\n",
    "import pyloudnorm as pyln\n",
    "import noisereduce as nr\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (1) Whisper  [default 'small']\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "if importlib.util.find_spec('faster_whisper') is None:\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'faster-whisper'], check=True)\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "_whisper = None\n",
    "def get_whisper(model_size='small'):\n",
    "    global _whisper\n",
    "    if _whisper is None or getattr(_whisper, '_size', None) != model_size:\n",
    "        _whisper = WhisperModel(model_size, device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                                compute_type='float16' if torch.cuda.is_available() else 'int8')\n",
    "        _whisper._size = model_size\n",
    "    return _whisper\n",
    "\n",
    "def trascrivi_reference(audio_path, lang='it', whisper_size='small'):\n",
    "    wm = get_whisper(whisper_size)\n",
    "    segments, info = wm.transcribe(audio_path, language=lang, vad_filter=True)\n",
    "    return ' '.join([s.text.strip() for s in segments]).strip()\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (2) Preprocessing testo IT\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "def preprocessa_testo_it(testo: str):\n",
    "    testo = testo.replace('\u00ab','').replace('\u00bb','')\n",
    "    testo = testo.replace('\"','')\n",
    "    testo = testo.replace('\\u2018',\"'\").replace('\\u2019',\"'\")\n",
    "    testo = re.sub(r'\\.(\\s+|$)', r',\\1', testo)\n",
    "    testo = testo.replace('\u2026', ',')\n",
    "    testo = re.sub(r'\\.{2,}', ',', testo)\n",
    "    testo = testo.replace('\u2014', ',').replace('\u2013', ',')\n",
    "    testo = re.sub(r'[()[\\]{}]', '', testo)\n",
    "    testo = re.sub(r'\\s+', ' ', testo).strip()\n",
    "    return testo\n",
    "\n",
    "def split_testo_chunked(testo, max_chars=400):\n",
    "    frasi = re.split(r'(?<=[,.!?])\\s+', testo)\n",
    "    chunks, current = [], ''\n",
    "    for f in frasi:\n",
    "        if len(current) + len(f) + 1 <= max_chars:\n",
    "            current += (' ' if current else '') + f\n",
    "        else:\n",
    "            if current: chunks.append(current.strip())\n",
    "            current = f\n",
    "    if current: chunks.append(current.strip())\n",
    "    return chunks if chunks else [testo]\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (3) Reference: SNR score + 24kHz\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "def trim_silence(audio, threshold=-40, padding_ms=120):\n",
    "    start = detect_leading_silence(audio, silence_threshold=threshold)\n",
    "    end   = detect_leading_silence(audio.reverse(), silence_threshold=threshold)\n",
    "    trimmed = audio[start : len(audio) - end]\n",
    "    return AudioSegment.silent(duration=padding_ms) + trimmed + AudioSegment.silent(duration=padding_ms)\n",
    "\n",
    "def snr_score(chunk):\n",
    "    samples = np.array(chunk.get_array_of_samples(), dtype=np.float64)\n",
    "    if len(samples) == 0: return 0.0\n",
    "    signal_power = np.mean(samples ** 2)\n",
    "    smoothed = np.convolve(samples, np.ones(5) / 5, mode='same')\n",
    "    noise_est = np.var(samples - smoothed)\n",
    "    return signal_power / (noise_est + 1e-9)\n",
    "\n",
    "def prepara_reference(filepath, denoise=False, target_ms=18_000):\n",
    "    audio = AudioSegment.from_file(filepath)\n",
    "    audio = audio.set_channels(1).set_frame_rate(24000)\n",
    "    audio = trim_silence(audio)\n",
    "    if len(audio) > target_ms:\n",
    "        step = 1500\n",
    "        chunks = [audio[i:i+target_ms] for i in range(0, len(audio) - target_ms, step)]\n",
    "        audio = max(chunks, key=snr_score)\n",
    "    tmp = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)\n",
    "    audio.export(tmp.name, format='wav')\n",
    "    if denoise:\n",
    "        import soundfile as _sf; import noisereduce as _nr\n",
    "        data, sr = _sf.read(tmp.name)\n",
    "        data = _nr.reduce_noise(y=data, sr=sr, prop_decrease=0.35)\n",
    "        _sf.write(tmp.name, data, sr)\n",
    "    return tmp.name\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (4) Post-processing\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "def postprocessa_output(wav_path, target_lufs=-18.0):\n",
    "    audio = AudioSegment.from_wav(wav_path)\n",
    "    audio = trim_silence(audio, threshold=-50, padding_ms=150)\n",
    "    audio.export(wav_path, format='wav')\n",
    "    data, rate = sf.read(wav_path)\n",
    "    meter = pyln.Meter(rate)\n",
    "    loudness = meter.integrated_loudness(data)\n",
    "    if loudness > -70:\n",
    "        data = pyln.normalize.loudness(data, loudness, target_lufs)\n",
    "        sf.write(wav_path, data, rate)\n",
    "    return wav_path\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (5) Target durata \u2013 pyrubberband\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "def durata_wav(path):\n",
    "    data, rate = sf.read(path); return len(data) / rate\n",
    "\n",
    "def adatta_durata(wav_path, target_sec):\n",
    "    data, sr = sf.read(wav_path)\n",
    "    current_sec = len(data) / sr\n",
    "    rate = max(0.7, min(1.4, current_sec / target_sec))\n",
    "    stretched = pyrb.time_stretch(data.astype(np.float32), sr, 1.0 / rate)\n",
    "    sf.write(wav_path, stretched, sr)\n",
    "    return wav_path, rate, current_sec\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (6) Cache voice_clone_prompt\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "def _hash_file(path):\n",
    "    with open(path, 'rb') as f: return hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "_prompt_cache = {}\n",
    "def get_voice_prompt(ref_wav, ref_text, xvec_only):\n",
    "    key = (_hash_file(ref_wav), ref_text, bool(xvec_only))\n",
    "    if key not in _prompt_cache:\n",
    "        _prompt_cache[key] = model.create_voice_clone_prompt(\n",
    "            ref_audio=ref_wav, ref_text=ref_text, x_vector_only_mode=bool(xvec_only))\n",
    "    return _prompt_cache[key]\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (7) Preset IT + gen_kwargs builder\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "PRESET = {\n",
    "    '\ud83c\uddee\ud83c\uddf9 IT \u2013 Naturale YouTube (consigliato)': dict(\n",
    "        temperature=0.85, top_p=0.95, top_k=50, repetition_penalty=1.06, max_new_tokens=3072),\n",
    "    '\ud83c\uddee\ud83c\uddf9 IT \u2013 Super stabile (meno errori)': dict(\n",
    "        temperature=0.70, top_p=0.85, top_k=40, repetition_penalty=1.10, max_new_tokens=3072),\n",
    "    '\ud83c\uddee\ud83c\uddf9 IT \u2013 Pi\u00f9 espressivo (rischio errori)': dict(\n",
    "        temperature=1.00, top_p=0.95, top_k=70, repetition_penalty=1.05, max_new_tokens=3072),\n",
    "}\n",
    "\n",
    "def applica_preset(nome):\n",
    "    p = PRESET[nome]\n",
    "    return p['temperature'], p['top_p'], p['top_k'], p['repetition_penalty'], p['max_new_tokens']\n",
    "\n",
    "def build_gen_kwargs(max_new_tokens, top_k, top_p, temperature, repetition_penalty):\n",
    "    return dict(max_new_tokens=int(max_new_tokens), do_sample=True,\n",
    "                top_k=int(top_k), top_p=float(top_p), temperature=float(temperature),\n",
    "                repetition_penalty=float(repetition_penalty),\n",
    "                subtalker_dosample=True, subtalker_top_k=int(top_k),\n",
    "                subtalker_top_p=float(top_p), subtalker_temperature=float(temperature))\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (8a) Voice Clone\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "def genera_voice_clone(testo, ref_file, ref_text_manual, auto_ref_text, whisper_size,\n",
    "                       xvec_only, use_cache, denoise_ref, do_postprocess, use_chunking,\n",
    "                       preset_name, temperature, top_p, top_k, rep_pen, max_tok,\n",
    "                       target_min, target_sec):\n",
    "    if not testo or not testo.strip(): raise gr.Error('Inserisci un testo.')\n",
    "    if ref_file is None: raise gr.Error('Carica un audio di riferimento.')\n",
    "    if MODEL_TYPE != 'clone':\n",
    "        raise gr.Error(f'Modello attivo ({MODEL_ID}) non \u00e8 un modello Base.')\n",
    "    t0 = time.time()\n",
    "    target_totale = float(target_min) * 60 + float(target_sec)\n",
    "    testo_proc = preprocessa_testo_it(testo)\n",
    "    ref_wav = prepara_reference(ref_file, denoise=denoise_ref)\n",
    "    ref_text = (ref_text_manual or '').strip()\n",
    "    if (not xvec_only) and (not ref_text) and auto_ref_text:\n",
    "        ref_text = trascrivi_reference(ref_wav, lang='it', whisper_size=whisper_size)\n",
    "    warn = ''\n",
    "    if (not xvec_only) and (not ref_text):\n",
    "        warn = '\u26a0\ufe0f ref_text vuoto: attiva auto-trascrizione o inseriscilo manualmente.'\n",
    "    gen_kwargs = build_gen_kwargs(max_tok, top_k, top_p, temperature, rep_pen)\n",
    "    chunks = split_testo_chunked(testo_proc) if (use_chunking and len(testo_proc) > 400) else [testo_proc]\n",
    "    if use_cache: prompt = get_voice_prompt(ref_wav, ref_text, xvec_only)\n",
    "    all_wavs = []\n",
    "    for chunk in chunks:\n",
    "        if use_cache:\n",
    "            wavs, sr = model.generate_voice_clone(text=chunk, language='Italian', voice_clone_prompt=prompt, **gen_kwargs)\n",
    "        else:\n",
    "            wavs, sr = model.generate_voice_clone(text=chunk, language='Italian', ref_audio=ref_wav,\n",
    "                                                   ref_text=ref_text, x_vector_only_mode=bool(xvec_only), **gen_kwargs)\n",
    "        all_wavs.append(wavs[0])\n",
    "    final_wav = np.concatenate(all_wavs) if len(all_wavs) > 1 else all_wavs[0]\n",
    "    out_path = '/content/output_qwen3_clone.wav'\n",
    "    sf.write(out_path, final_wav, sr)\n",
    "    stretch = 1.0\n",
    "    if target_totale > 0: out_path, stretch, _ = adatta_durata(out_path, target_totale)\n",
    "    if do_postprocess: postprocessa_output(out_path)\n",
    "    dur = durata_wav(out_path)\n",
    "    info = f'\u2705 {time.time()-t0:.1f}s | {len(chunks)} chunk(s) | durata {dur:.1f}s | stretch {stretch:.3f}x'\n",
    "    if target_totale > 0: info += f' | delta {dur-target_totale:+.1f}s'\n",
    "    if warn: info = warn + '\\n' + info\n",
    "    return out_path, testo_proc, ref_text, info\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (8b) Voice Design\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "def genera_voice_design(testo, voice_desc, do_postprocess, use_chunking,\n",
    "                        preset_name, temperature, top_p, top_k, rep_pen, max_tok,\n",
    "                        target_min, target_sec):\n",
    "    if not testo or not testo.strip(): raise gr.Error('Inserisci un testo.')\n",
    "    if not voice_desc or not voice_desc.strip(): raise gr.Error('Inserisci una descrizione.')\n",
    "    if MODEL_TYPE != 'design':\n",
    "        raise gr.Error(f'Modello attivo ({MODEL_ID}) non \u00e8 VoiceDesign.')\n",
    "    t0 = time.time()\n",
    "    target_totale = float(target_min) * 60 + float(target_sec)\n",
    "    testo_proc = preprocessa_testo_it(testo)\n",
    "    gen_kwargs = build_gen_kwargs(max_tok, top_k, top_p, temperature, rep_pen)\n",
    "    chunks = split_testo_chunked(testo_proc) if (use_chunking and len(testo_proc) > 400) else [testo_proc]\n",
    "    all_wavs = []\n",
    "    for chunk in chunks:\n",
    "        wavs, sr = model.generate_voice_design(text=chunk, language='Italian', voice_description=voice_desc, **gen_kwargs)\n",
    "        all_wavs.append(wavs[0])\n",
    "    final_wav = np.concatenate(all_wavs) if len(all_wavs) > 1 else all_wavs[0]\n",
    "    out_path = '/content/output_qwen3_design.wav'\n",
    "    sf.write(out_path, final_wav, sr)\n",
    "    stretch = 1.0\n",
    "    if target_totale > 0: out_path, stretch, _ = adatta_durata(out_path, target_totale)\n",
    "    if do_postprocess: postprocessa_output(out_path)\n",
    "    dur = durata_wav(out_path)\n",
    "    return out_path, testo_proc, f'\u2705 {time.time()-t0:.1f}s | {len(chunks)} chunk(s) | {dur:.1f}s | stretch {stretch:.3f}x'\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (8c) Custom Voice\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "CUSTOM_VOICES = ['Chelsie','Ethan','Emma','Dylan','Chloe','Aria','Marcus','Zara','Leo']\n",
    "\n",
    "def genera_custom_voice(testo, voice_dd, voice_manual, do_postprocess, use_chunking,\n",
    "                        preset_name, temperature, top_p, top_k, rep_pen, max_tok,\n",
    "                        target_min, target_sec):\n",
    "    if not testo or not testo.strip(): raise gr.Error('Inserisci un testo.')\n",
    "    if MODEL_TYPE != 'custom':\n",
    "        raise gr.Error(f'Modello attivo ({MODEL_ID}) non \u00e8 CustomVoice.')\n",
    "    voice_name = voice_manual.strip() if voice_manual.strip() else voice_dd\n",
    "    t0 = time.time()\n",
    "    target_totale = float(target_min) * 60 + float(target_sec)\n",
    "    testo_proc = preprocessa_testo_it(testo)\n",
    "    gen_kwargs = build_gen_kwargs(max_tok, top_k, top_p, temperature, rep_pen)\n",
    "    chunks = split_testo_chunked(testo_proc) if (use_chunking and len(testo_proc) > 400) else [testo_proc]\n",
    "    all_wavs = []\n",
    "    for chunk in chunks:\n",
    "        wavs, sr = model.generate(text=chunk, language='Italian', voice_name=voice_name, **gen_kwargs)\n",
    "        all_wavs.append(wavs[0])\n",
    "    final_wav = np.concatenate(all_wavs) if len(all_wavs) > 1 else all_wavs[0]\n",
    "    out_path = '/content/output_qwen3_custom.wav'\n",
    "    sf.write(out_path, final_wav, sr)\n",
    "    stretch = 1.0\n",
    "    if target_totale > 0: out_path, stretch, _ = adatta_durata(out_path, target_totale)\n",
    "    if do_postprocess: postprocessa_output(out_path)\n",
    "    dur = durata_wav(out_path)\n",
    "    return out_path, testo_proc, f'\u2705 {time.time()-t0:.1f}s | {voice_name} | {len(chunks)} chunk(s) | {dur:.1f}s'\n",
    "\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "# (9) Gradio UI v3 \u2014 3 tab\n",
    "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "def _shared_controls(suffix):\n",
    "    do_pp    = gr.Checkbox(label='\ud83c\udf9a\ufe0f Normalizza output (-18 LUFS)', value=True)\n",
    "    chunking = gr.Checkbox(label='\u2702\ufe0f Chunking testi lunghi (>400 char)', value=True)\n",
    "    preset   = gr.Dropdown(label='\ud83c\udf9b\ufe0f Preset IT', choices=list(PRESET.keys()),\n",
    "                           value='\ud83c\uddee\ud83c\uddf9 IT \u2013 Naturale YouTube (consigliato)')\n",
    "    gr.Markdown('### \ud83c\udfac Target durata (opzionale)')\n",
    "    with gr.Row():\n",
    "        t_min = gr.Number(label='Min', value=0, minimum=0, maximum=60, step=1)\n",
    "        t_sec = gr.Number(label='Sec', value=0, minimum=0, maximum=59, step=1)\n",
    "    with gr.Accordion('\u2699\ufe0f Avanzate', open=False):\n",
    "        temp = gr.Slider(label='temperature', minimum=0.3, maximum=1.3, value=0.85, step=0.05)\n",
    "        tp   = gr.Slider(label='top_p', minimum=0.5, maximum=1.0, value=0.95, step=0.05)\n",
    "        tk   = gr.Slider(label='top_k', minimum=1, maximum=200, value=50, step=1)\n",
    "        rp   = gr.Slider(label='repetition_penalty', minimum=1.0, maximum=1.3, value=1.06, step=0.01)\n",
    "        mt   = gr.Slider(label='max_new_tokens', minimum=512, maximum=8192, value=3072, step=256)\n",
    "    preset.change(fn=applica_preset, inputs=preset, outputs=[temp, tp, tk, rp, mt])\n",
    "    return do_pp, chunking, preset, t_min, t_sec, temp, tp, tk, rp, mt\n",
    "\n",
    "with gr.Blocks(title='Qwen3-TTS Pro IT v3') as ui:\n",
    "    gr.Markdown('# \ud83c\udfa4 Qwen3\u2011TTS \u2014 Pro Italiano v3')\n",
    "    gr.Markdown(\n",
    "        f'**Modello:** `{MODEL_ID}` | **Tipo:** `{MODEL_TYPE}` | **SR:** {SAMPLE_RATE} Hz\\n\\n'\n",
    "        '**Fix v2:** bfloat16 \u00b7 24kHz \u00b7 pyrubberband \u00b7 denoise 0.35 | '\n",
    "        '**Nuovo v3:** Whisper small \u00b7 SNR ref \u00b7 Chunking \u00b7 VoiceDesign \u00b7 CustomVoice'\n",
    "    )\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem('\ud83c\udfa4 Voice Clone'):\n",
    "            gr.Markdown('Clona una voce da audio di riferimento. Richiede modello `*-Base`.')\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    ref_audio  = gr.Audio(label='\ud83c\udfa4 Reference (WAV/MP3)', type='filepath', sources=['upload'])\n",
    "                    ref_text_m = gr.Textbox(label='\ud83d\udcdd Trascrizione reference', placeholder='Opzionale ma consigliato', lines=2)\n",
    "                    auto_ref   = gr.Checkbox(label='\ud83e\udde0 Auto\u2011trascrivi con Whisper', value=True)\n",
    "                    wh_size    = gr.Dropdown(label='Whisper model', choices=['tiny','base','small'], value='small')\n",
    "                    xvec       = gr.Checkbox(label='\u26a1 x_vector_only_mode', value=False)\n",
    "                    cache      = gr.Checkbox(label='\u26a1 Cache voice_clone_prompt', value=True)\n",
    "                    den_ref    = gr.Checkbox(label='\ud83d\udd07 Denoise reference', value=False)\n",
    "                    do_pp_vc, chunking_vc, preset_vc, tmin_vc, tsec_vc, temp_vc, tp_vc, tk_vc, rp_vc, mt_vc = _shared_controls('vc')\n",
    "                with gr.Column(scale=1):\n",
    "                    testo_vc = gr.Textbox(label='\ud83d\udcc4 Testo Italiano', lines=12, placeholder='Incolla il tuo voiceover\u2026')\n",
    "                    btn_vc   = gr.Button('\ud83d\ude80 Genera Voice Clone', variant='primary')\n",
    "                    audio_vc = gr.Audio(label='\ud83d\udd0a Output', type='filepath')\n",
    "                    proc_vc  = gr.Textbox(label='Testo preprocessato', lines=3)\n",
    "                    rtext_vc = gr.Textbox(label='ref_text usato', lines=2)\n",
    "                    info_vc  = gr.Textbox(label='Info', lines=3)\n",
    "            btn_vc.click(fn=genera_voice_clone,\n",
    "                inputs=[testo_vc, ref_audio, ref_text_m, auto_ref, wh_size, xvec, cache, den_ref,\n",
    "                        do_pp_vc, chunking_vc, preset_vc, temp_vc, tp_vc, tk_vc, rp_vc, mt_vc, tmin_vc, tsec_vc],\n",
    "                outputs=[audio_vc, proc_vc, rtext_vc, info_vc])\n",
    "\n",
    "        with gr.TabItem('\ud83c\udfa8 Voice Design'):\n",
    "            gr.Markdown('Crea voce da descrizione testuale. Richiede `*-VoiceDesign`.')\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    vdesc = gr.Textbox(label='\ud83c\udfa8 Descrizione voce',\n",
    "                        placeholder='Es: Voce femminile italiana, calda, ideale per documentari.', lines=4)\n",
    "                    do_pp_vd, chunking_vd, preset_vd, tmin_vd, tsec_vd, temp_vd, tp_vd, tk_vd, rp_vd, mt_vd = _shared_controls('vd')\n",
    "                with gr.Column(scale=1):\n",
    "                    testo_vd = gr.Textbox(label='\ud83d\udcc4 Testo Italiano', lines=12)\n",
    "                    btn_vd   = gr.Button('\ud83c\udfa8 Genera Voice Design', variant='primary')\n",
    "                    audio_vd = gr.Audio(label='\ud83d\udd0a Output', type='filepath')\n",
    "                    proc_vd  = gr.Textbox(label='Testo preprocessato', lines=3)\n",
    "                    info_vd  = gr.Textbox(label='Info', lines=2)\n",
    "            btn_vd.click(fn=genera_voice_design,\n",
    "                inputs=[testo_vd, vdesc, do_pp_vd, chunking_vd, preset_vd,\n",
    "                        temp_vd, tp_vd, tk_vd, rp_vd, mt_vd, tmin_vd, tsec_vd],\n",
    "                outputs=[audio_vd, proc_vd, info_vd])\n",
    "\n",
    "        with gr.TabItem('\ud83d\udc64 Custom Voice'):\n",
    "            gr.Markdown('9 voci predefinite Qwen. Richiede `*-CustomVoice`.')\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    vdd  = gr.Dropdown(label='\ud83d\udc64 Voce predefinita', choices=CUSTOM_VOICES, value='Chelsie')\n",
    "                    vman = gr.Textbox(label='\u270f\ufe0f Nome voce manuale (sovrascrive dropdown)', lines=1, placeholder='Lascia vuoto per dropdown')\n",
    "                    do_pp_cv, chunking_cv, preset_cv, tmin_cv, tsec_cv, temp_cv, tp_cv, tk_cv, rp_cv, mt_cv = _shared_controls('cv')\n",
    "                with gr.Column(scale=1):\n",
    "                    testo_cv = gr.Textbox(label='\ud83d\udcc4 Testo Italiano', lines=12)\n",
    "                    btn_cv   = gr.Button('\ud83d\udc64 Genera Custom Voice', variant='primary')\n",
    "                    audio_cv = gr.Audio(label='\ud83d\udd0a Output', type='filepath')\n",
    "                    proc_cv  = gr.Textbox(label='Testo preprocessato', lines=3)\n",
    "                    info_cv  = gr.Textbox(label='Info', lines=2)\n",
    "            btn_cv.click(fn=genera_custom_voice,\n",
    "                inputs=[testo_cv, vdd, vman, do_pp_cv, chunking_cv, preset_cv,\n",
    "                        temp_cv, tp_cv, tk_cv, rp_cv, mt_cv, tmin_cv, tsec_cv],\n",
    "                outputs=[audio_cv, proc_cv, info_cv])\n",
    "\n",
    "ui.queue(default_concurrency_limit=1)\n",
    "ui.launch(share=True)\n"
   ],
   "metadata": {"id": "cell_ui"},
   "execution_count": null,
   "outputs": []
  }
 ]
}